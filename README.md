# Conversational Agents - Master's Course Workshop (UniversitÃ© CÃ´te dâ€™Azur)

This repository contains the practical materials I designed and taught for the **Conversational Agents AI Course** at UniversitÃ© CÃ´te dâ€™Azur (M2 - Master in Artificial Intelligence, Dec 2024 â€“ Jan 2025).

## ðŸ§  Course Overview

- **Duration**: 2 months, 7 workshops
- **Audience**: Masterâ€™s students in Artificial Intelligence
- **Focus**: Design and implementation of Conversational Agents using **Large Language Models**, **FastAPI**, and **Langchain**

## ðŸ› ï¸ Technologies

- Python 3.11+
- FastAPI
- Langchain

## ðŸ“š Content Summary

| Workshop | Topics |
|----------|--------|
| 1        | Introduction to LLMs and Chatbots |
| 2        | APIs and REST principles |
| 3        | FastAPI fundamentals |
| 4        | Langchain Chains & Tools |
| 5        | Function Calling with LLMs |
| 6        | Evaluation & Prompt Engineering |
| 7        | Group Projects & Demo Day |

## âœï¸ About the Instructor

This course was designed and taught by [Nathan Rihet](https://www.linkedin.com/in/nathan-rihet/?locale=en_US), Full-Stack & AI Engineer, as part of an academic collaboration with UniversitÃ© CÃ´te dâ€™Azur.


> Helping students bridge the gap between **AI theory** and **real-world applications** through hands-on LLM-based projects.

---

Feel free to use, adapt, and contribute.

## Architecture

```
C:.
â”œâ”€â”€â”€api/                    # Gestion des routes et endpoints de l'API
â”‚   â”œâ”€â”€â”€endpoints/         # Endpoints spÃ©cifiques par fonctionnalitÃ©
â”‚   â”‚   â””â”€â”€â”€chat.py       # Endpoint pour les fonctionnalitÃ©s de chat
â”‚   â””â”€â”€â”€router.py         # Router principal regroupant tous les endpoints
â”œâ”€â”€â”€core/                  # Configuration et Ã©lÃ©ments centraux de l'application
â”œâ”€â”€â”€models/               # ModÃ¨les de donnÃ©es Pydantic
â”‚   â””â”€â”€â”€chat.py          # ModÃ¨les pour les requÃªtes/rÃ©ponses de chat
â”œâ”€â”€â”€services/            # Services mÃ©tier
â”‚   â””â”€â”€â”€llm_service.py   # Service d'interaction avec le LLM
â”œâ”€â”€â”€utils/               # Utilitaires et helpers
â””â”€â”€â”€main.py             # Point d'entrÃ©e de l'application
```

## Installation et Configuration

### PrÃ©requis
- Python 3.11+ (ici : https://www.python.org/downloads/release/python-3110/ il faut redÃ©marrer aprÃ¨s installation pour avoir le $PATH sur l'OS)
- Visual Studio Code avec l'extension Python
- Une clÃ© OpenAI que je vais vous fournir

### Installation

1. **Cloner le projet**
```bash
git clone <URL_DU_DEPOT>
cd <NOM_DU_PROJET>
```

2. **CrÃ©er l'environnement virtuel**
```bash
python -m venv venv
```

3. **Activer l'environnement virtuel**
- Windows :
```bash
.\venv\Scripts\activate
```
- macOS/Linux :
```bash
source venv/bin/activate
```

4. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

5. **Configurer la clÃ© API OpenAI**
CrÃ©er un fichier `.env` Ã  la racine du projet :
```
OPENAI_API_KEY=votre-clÃ©-api-openai
```


## Explication des Composants

### 1. Main Application (`main.py`)
```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
```
- Point d'entrÃ©e de l'application
- Configure FastAPI et les middlewares
- Initialise les routes

### 2. ModÃ¨les (`models/chat.py`)
```python
class ChatRequest(BaseModel):
    message: str
```
- DÃ©finit la structure des donnÃ©es entrantes/sortantes
- Utilise Pydantic pour la validation des donnÃ©es
- Version simple pour dÃ©buter, extensible pour le contexte

### 3. Service LLM (`services/llm_service.py`)
```python
class LLMService:
    def __init__(self):
        self.llm = ChatOpenAI(...)
```
- GÃ¨re l'interaction avec le modÃ¨le de langage
- Configure le client OpenAI
- Traite les messages et le contexte

### 4. Router API (`api/router.py`)
```python
@router.post("/chat")
async def chat(request: ChatRequest) -> ChatResponse:
```
- DÃ©finit les endpoints de l'API
- GÃ¨re les requÃªtes HTTP
- Valide les donnÃ©es entrantes

## Utilisation de l'API

### Version Simple
```bash
curl -X 'POST' \
  'http://localhost:8000/chat/simple' \
  -H 'Content-Type: application/json' \
  -d '{"message": "Bonjour!"}'
```

### Version avec Contexte
```bash
curl -X 'POST' \
  'http://localhost:8000/chat/with-context' \
  -H 'Content-Type: application/json' \
  -d '{
    "message": "Bonjour!",
    "context": [
      {"role": "user", "content": "Comment vas-tu?"},
      {"role": "assistant", "content": "Je vais bien, merci!"}
    ]
  }'
```

## Debugging avec VS Code

1. Ouvrir le projet dans VS Code
2. Aller dans la section "Run and Debug" (Ctrl + Shift + D)
3. SÃ©lectionner la configuration "Python: FastAPI"
4. Appuyer sur F5 ou cliquer sur le bouton Play
5. DÃ©marrer Swagger : http://127.0.0.1:8000/docs

## Structure de l'API

### Endpoints Disponibles

- `/chat/simple` : Version basique sans contexte
- `/chat/with-context` : Version avancÃ©e avec gestion du contexte

### Flux de DonnÃ©es

1. La requÃªte arrive sur l'endpoint
2. Les modÃ¨les Pydantic valident les donnÃ©es
3. Le service LLM traite la demande
4. La rÃ©ponse est formatÃ©e et renvoyÃ©e

## Progression PÃ©dagogique

1. **DÃ©marrer avec la version simple**
   - Comprendre la structure de base
   - Tester les appels API simples

2. **Ã‰voluer vers la version avec contexte**
   - Ajouter la gestion de l'historique
   - Comprendre l'importance du contexte dans les LLM

3. **Explorer les fonctionnalitÃ©s avancÃ©es**
   - ImplÃ©menter des prompts personnalisÃ©s
   - GÃ©rer diffÃ©rents types de rÃ©ponses

## DÃ©pannage

### ProblÃ¨mes Courants

1. **Erreur de clÃ© API**
   - VÃ©rifier le fichier `.env`
   - S'assurer que la clÃ© est valide

2. **Erreurs de dÃ©pendances**
   - VÃ©rifier l'activation du venv
   - RÃ©installer les requirements

3. **Erreurs de contexte**
   - VÃ©rifier le format du contexte
   - S'assurer que les rÃ´les sont valides

4. **Powershell**
   - Si les droits admin ne sont pas prÃ©sent : ''Set-ExecutionPolicy Unrestricted -Scope CurrentUser -Force''

## Ressources

- [Documentation FastAPI](https://fastapi.tiangolo.com/)
- [Documentation LangChain](https://python.langchain.com/)
- [API OpenAI](https://platform.openai.com/docs/api-reference)
